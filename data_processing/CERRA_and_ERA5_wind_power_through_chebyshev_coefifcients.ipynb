{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harish/Desktop/Modeling-Frontal-Low-Level-Jets-and-Associated-Extreme-Wind-Ramps/data_processing/libraries.py:151: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(f\"{root_dir}/windturbines.txt\", delim_whitespace=True,header=None)\n",
      "/home/harish/Desktop/Modeling-Frontal-Low-Level-Jets-and-Associated-Extreme-Wind-Ramps/data_processing/libraries.py:156: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  power_curve_type_1 = pd.read_csv(f\"{root_dir}/wind-turbine-1.tbl\",delim_whitespace=True,skiprows=2,header=None,usecols=[0,2])\n",
      "/home/harish/Desktop/Modeling-Frontal-Low-Level-Jets-and-Associated-Extreme-Wind-Ramps/data_processing/libraries.py:157: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  power_curve_type_2 = pd.read_csv(f\"{root_dir}/wind-turbine-2.tbl\",delim_whitespace=True,skiprows=2,header=None,usecols=[0,2])\n",
      "/home/harish/Desktop/Modeling-Frontal-Low-Level-Jets-and-Associated-Extreme-Wind-Ramps/data_processing/libraries.py:158: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  power_curve_type_3 = pd.read_csv(f\"{root_dir}/wind-turbine-3.tbl\",delim_whitespace=True,skiprows=2,header=None,usecols=[0,2])\n",
      "/home/harish/Desktop/Modeling-Frontal-Low-Level-Jets-and-Associated-Extreme-Wind-Ramps/data_processing/libraries.py:159: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  power_curve_type_4 = pd.read_csv(f\"{root_dir}/wind-turbine-4.tbl\",delim_whitespace=True,skiprows=2,header=None,usecols=[0,2])\n",
      "/home/harish/Desktop/Modeling-Frontal-Low-Level-Jets-and-Associated-Extreme-Wind-Ramps/data_processing/libraries.py:160: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  power_curve_type_5 = pd.read_csv(f\"{root_dir}/wind-turbine-5.tbl\",delim_whitespace=True,skiprows=2,header=None,usecols=[0,2])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import os, sys\n",
    "import glob\n",
    "import zarr\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "import metpy\n",
    "\n",
    "root_dir = '/home/harish/Desktop/Modeling-Frontal-Low-Level-Jets-and-Associated-Extreme-Wind-Ramps/' if os.path.exists('/home/harish/Desktop/Modeling-Frontal-Low-Level-Jets-and-Associated-Extreme-Wind-Ramps/') else '/media/ssd_4tb_qvo/Modeling-Frontal-Low-Level-Jets-and-Associated-Extreme-Wind-Ramps/'\n",
    "\n",
    "from data_processing.libraries import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we would like to make sure that the reference height levels cover the profiler levels and NOW23 levels, including the 0 m level.\n",
    "profilers_levels = np.array([10] + list(range(100, 501, 25)))\n",
    "NOW23_levels = np.array([10] + list(range(20, 301, 20)) + [400, 500])\n",
    "CERRA_levels = np.array([10,15, 30, 50., 75., 100., 150., 200., 250., 300., 400., 500])\n",
    "# combine the two arrays and remove duplicates\n",
    "ref_H = np.unique(np.concatenate((np.array([0]),profilers_levels, NOW23_levels, CERRA_levels)))\n",
    "\n",
    "# These variables are used while creating the Chebyshev coefficients\n",
    "poly_order = 4\n",
    "CPtype = 1\n",
    "\n",
    "def normalize(H,ref_H=ref_H):\n",
    "    '''\n",
    "    Normalizes the height levels between -1 and 1\n",
    "    ref_H: A vector of reference height levels, in our case CERRA levels\n",
    "    H: A vector of height levels\n",
    "    '''\n",
    "    a = 2 / (np.max(ref_H) - np.min(ref_H))\n",
    "    b = - (np.max(ref_H) + np.min(ref_H)) / (np.max(ref_H) - np.min(ref_H))\n",
    "    Hn = a * ref_H + b\n",
    "\n",
    "    Hn = np.interp(H, ref_H, Hn)\n",
    "    return Hn\n",
    "\n",
    "def Chebyshev_Basu(x, poly_order=poly_order, CPtype=CPtype):\n",
    "    '''\n",
    "    This function computes the Chebyshev polynomials, according to the equations in Mason, J. C., & Handscomb, D. C. (2002). Chebyshev polynomials. Chapman and Hall/CRC.\n",
    "    x: input variable, between -1 and 1\n",
    "    poly_order: order of polynomials\n",
    "    CPtype: 1 or 2, according to the publication\n",
    "    '''\n",
    "    if x.ndim == 1:\n",
    "        x = x[:, np.newaxis]\n",
    "\n",
    "    CP = np.zeros((len(x), poly_order + 1))\n",
    "\n",
    "    CP[:, 0] = 1  # T0(x) = 1\n",
    "    if poly_order >= 1:\n",
    "        if CPtype == 1:  # Chebyshev polynomial of first kind\n",
    "            CP[:, 1] = x.flatten()  # T1(x) = x\n",
    "        else:  # Chebyshev polynomial of second kind\n",
    "            CP[:, 1] = 2 * x.flatten()  # T1(x) = 2x\n",
    "        if poly_order >= 2:\n",
    "            for n in range(2, poly_order + 1):\n",
    "                CP[:, n] = 2 * x.flatten() * CP[:, n - 1] - CP[:, n - 2]\n",
    "    return CP\n",
    "\n",
    "def Chebyshev_Coeff(H, U,poly_order=poly_order,CPtype=CPtype,ref_H=ref_H):\n",
    "    '''\n",
    "    This function computes the Chebyshev coefficients through inverse transform of system of linear equations\n",
    "    H: height levels, in their useual units\n",
    "    U: wind speed at the height levels\n",
    "    p: polynomial order\n",
    "    CPtype: 1 or 2, according to the publication\n",
    "    '''\n",
    "    H = H.flatten()\n",
    "    U = U.flatten()\n",
    "\n",
    "    # Normalize H\n",
    "    Hn = normalize(H, ref_H=ref_H)\n",
    "    \n",
    "    # Remove NaN values\n",
    "    Indx = np.where(~np.isnan(U))[0]\n",
    "    Ha = Hn[Indx]\n",
    "    Ua = U[Indx]\n",
    "    N = len(Ua)\n",
    "\n",
    "    # Linearly extrapolate wind values at the boundaries\n",
    "    #spline_left = interp1d(Ha, Ua, kind='linear', fill_value='extrapolate')\n",
    "    #Uax = spline_left([-1])\n",
    "\n",
    "    #spline_right = interp1d(Ha, Ua, kind='linear', fill_value='extrapolate')\n",
    "    #Uay = spline_right([1])\n",
    "    #Ua = np.concatenate([Uax, Ua, Uay])\n",
    "    #Ha = np.concatenate([-1 + np.zeros(1), Ha, 1 + np.zeros(1)])       # these two seems are unnecessary, which bring adidtional offset due to extrapolation.\n",
    "    \n",
    "    # Predict the gap-filled and denoised profile\n",
    "    PL = Chebyshev_Basu(Ha, poly_order=poly_order, CPtype=CPtype)\n",
    "    # Compute the coefficients C\n",
    "    Coeff = np.linalg.pinv(PL) @ Ua\n",
    "    return Coeff\n",
    "\n",
    "def WindProfile(Z,Coeff, poly_order=poly_order, CPtype=CPtype,ref_H=ref_H):\n",
    "    '''\n",
    "    This function computes the full level wind profile provided vertical levels and the Chebyshev coefficients\n",
    "    Z: height levels, in their useual units\n",
    "    Coeff: Chebysev coefficients\n",
    "    '''\n",
    "    # Normalize H\n",
    "    Hn = normalize(Z, ref_H=ref_H)\n",
    "    PL_full = Chebyshev_Basu(Hn, poly_order=poly_order, CPtype=CPtype)\n",
    "    Mp = PL_full @ Coeff\n",
    "    return Mp\n",
    "\n",
    "def chebyshev(z,y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Calculate Chebyshev coefficients for input y\"\"\"\n",
    "    return Chebyshev_Coeff(z, y)\n",
    "\n",
    "\n",
    "def chebyshev_vec(y: xr.DataArray, dim: str) -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Calculate Chebyshev coefficients for input y in `dim` direction.\n",
    "    Sample usage cheb = chebyshev_vec(ds, dim=\"heightAboveGround\")\n",
    "    \"\"\"\n",
    "    cheb = xr.apply_ufunc(\n",
    "        lambda y_i: xr.DataArray(chebyshev(y_i), dims=[\"coeff\"]),  # we need to make the output a DataArray with new dim\n",
    "        y,  # entire dataset as input\n",
    "        input_core_dims=[[dim]],  # dimension along which to apply chebyshev\n",
    "        output_core_dims=[[\"coeff\"]],  # dimension of the output, which is the coefficients\n",
    "        vectorize=True,  # vectorize the operation\n",
    "        dask=\"parallelized\",\n",
    "        dask_gufunc_kwargs={\"output_sizes\": {\"coeff\": poly_order+1}},\n",
    "    )\n",
    "    cheb.name = \"Chebyshev_coefficients\"\n",
    "    return cheb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CERRA wind power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CERRA_Cheybshev_zarr_store = '/data/harish/CERRA_wind_profiles_and_Chebyshev_coefficients/CERRA_Chebyshev_coefficients.zarr'\n",
    "CERRA_coordinates = xr.open_dataset('/home/harish/Ongoing_Research/CERRA_wind_profiles_and_Chebyshev_coefficients/CERRA_coordinates.nc')\n",
    "def find_nearest_indice(ds_lat,ds_lon,target_lat=None, target_lon=None):\n",
    "    '''\n",
    "    ds_lat: xarray DataArray of latitude\n",
    "    ds_lon: xarray DataArray of longitude\n",
    "    target_lat: float, target latitude\n",
    "    target_lon: float, target longitude\n",
    "    returns indices: tuple of indices of the nearest grid point\n",
    "    '''\n",
    "    distance_squared = (ds_lat - target_lat)**2 + (ds_lon - target_lon)**2\n",
    "    indices = np.unravel_index(np.nanargmin(distance_squared), distance_squared.shape)\n",
    "    #print(f'Closest indices in the order of latitude (y) and longitude (x) are : {indices}')\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [\n",
    "    find_nearest_indice(CERRA_coordinates.latitude, CERRA_coordinates.longitude, lat.item(), lon.item())\n",
    "    for lat, lon in zip(turbine_lats, turbine_lons)\n",
    "]\n",
    "# Split the list of tuples into separate lists for y and x indices\n",
    "y_indices, x_indices = zip(*indices)\n",
    "sample_ys = xr.DataArray(np.array(y_indices), dims=\"points\")\n",
    "sample_xs = xr.DataArray(np.array(x_indices), dims=\"points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in [1,2,3,4,5]:\n",
    "    time_range = ramp_periods[case-1]\n",
    "    ds = xr.open_zarr(CERRA_Cheybshev_zarr_store).Chebyshev_coefficients.isel(y=sample_ys,x=sample_xs).sel(time=slice(*time_range)).assign_coords(turbine_type=(\"points\", turbine_types), \n",
    "                      turbine_lat=(\"points\", turbine_lats), \n",
    "                      turbine_lon=(\"points\", turbine_lons),\n",
    "                      hub_heights=(\"points\", [hub_heights[i-1] for i in turbine_types]))\n",
    "    \n",
    "    # Apply the function along the 'time' dimension\n",
    "    ws = xr.apply_ufunc(\n",
    "        lambda z_i,y_i: xr.DataArray(WindProfile([z_i],y_i)),# dims=[\"heightAboveGround\"]),  \n",
    "        ds.hub_heights,  # Pass the height levels as an argument\n",
    "        ds.load(),  # Input dataset\n",
    "        input_core_dims=[[],[\"coeff\"]],  # Expect features to be the core dimension\n",
    "        #output_core_dims=[[\"heightAboveGround\"]],  # Output will have a new height dimension\n",
    "        vectorize=True,  # Ensures element-wise operation\n",
    "    )\n",
    "    tp = []\n",
    "    for i in range(ws.points.size):\n",
    "        turbine_type = ws.turbine_type[i].item()\n",
    "        ws_i = ws.sel(points=i)\n",
    "        tp.append(turbine_power(ws_i, power_curves[turbine_type - 1].values))\n",
    "    tp = xr.concat(tp, dim=\"points\")\n",
    "    tp = tp.sum(dim=\"points\")\n",
    "    \n",
    "    target_dir = os.path.join(root_dir, f'WES_dataset/CERRA/FLLJ_{case}')\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    tp.to_netcdf(os.path.join(target_dir, 'turbine_power.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERA5 wind power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine_sites = xr.Dataset(\n",
    "{\"latitude\": (\"points\", turbine_lats), \"longitude\": (\"points\", turbine_lons)}\n",
    ")\n",
    "\n",
    "for case in [2,3,4,5]:\n",
    "    time_range = ramp_periods[case-1]\n",
    "    ds = xr.open_zarr(\n",
    "        'gs://gcp-public-data-arco-era5/ar/model-level-1h-0p25deg.zarr-v1',\n",
    "        chunks=None,\n",
    "        storage_options=dict(token='anon'),\n",
    "    )\n",
    "\n",
    "    lu = find_nearest_indice(ds.latitude, ds.longitude, turbine_lats.max(),turbine_lons.min())\n",
    "    rd = find_nearest_indice(ds.latitude, ds.longitude, turbine_lats.min(),turbine_lons.max())\n",
    "\n",
    "    ds = ds[['u_component_of_wind', 'v_component_of_wind','geopotential']].sel(\n",
    "        hybrid=slice(120,None),\n",
    "        time=slice(*time_range),\n",
    "        latitude=slice(ds.latitude[lu[0]],ds.latitude[rd[0]]),\n",
    "        longitude=slice(ds.longitude[lu[1]],ds.longitude[rd[1]])).load()\n",
    "    ds = ds.isel(hybrid=slice(None,None,-1))\n",
    "\n",
    "    ws = np.sqrt(ds.u_component_of_wind**2 + ds.v_component_of_wind**2)\n",
    "    ds_ = xr.Dataset(\n",
    "        {\n",
    "            \"ws\": ws,\n",
    "            \"geopotential\": ds.geopotential / 9.81,\n",
    "        }\n",
    "    )\n",
    "    ds_ = ds_.where(ds_.geopotential <= 500,drop=True)\n",
    "\n",
    "    chebyshev = xr.apply_ufunc(\n",
    "        lambda z_i,y_i: xr.DataArray(Chebyshev_Coeff(z_i,y_i)),# dims=[\"heightAboveGround\"]),  \n",
    "        ds_.geopotential,  # Pass the height levels as an argument\n",
    "        ds_.ws,  # Input dataset\n",
    "        input_core_dims=[['hybrid'],[\"hybrid\"]],  # Expect features to be the core dimension\n",
    "        output_core_dims=[[\"coeff\"]],  # Output will have a new height dimension\n",
    "        vectorize=True,  # Ensures element-wise operation\n",
    "        dask=\"parallelized\",\n",
    "        dask_gufunc_kwargs={\"output_sizes\": {\"coeff\": poly_order+1}},\n",
    "    )\n",
    "\n",
    "    chebyshev = chebyshev.sel(latitude=turbine_sites.latitude, longitude=turbine_sites.longitude, method=\"nearest\").assign_coords(turbine_type=(\"points\", turbine_types), \n",
    "                        turbine_lat=(\"points\", turbine_lats), \n",
    "                        turbine_lon=(\"points\", turbine_lons),\n",
    "                        hub_heights=(\"points\", [hub_heights[i-1] for i in turbine_types]))\n",
    "    \n",
    "    # Apply the function along the 'time' dimension\n",
    "    ws = xr.apply_ufunc(\n",
    "        lambda z_i,y_i: xr.DataArray(WindProfile([z_i],y_i)),# dims=[\"heightAboveGround\"]),  \n",
    "        chebyshev.hub_heights,  # Pass the height levels as an argument\n",
    "        chebyshev.load(),  # Input dataset\n",
    "        input_core_dims=[[],[\"coeff\"]],  # Expect features to be the core dimension\n",
    "        #output_core_dims=[[\"heightAboveGround\"]],  # Output will have a new height dimension\n",
    "        vectorize=True,  # Ensures element-wise operation\n",
    "    )\n",
    "\n",
    "    tp = []\n",
    "    for i in range(ws.points.size):\n",
    "        turbine_type = ws.turbine_type[i].item()\n",
    "        ws_i = ws.sel(points=i)\n",
    "        tp.append(turbine_power(ws_i, power_curves[turbine_type - 1].values))\n",
    "    tp = xr.concat(tp, dim=\"points\")\n",
    "    tp = tp.sum(dim=\"points\")\n",
    "\n",
    "    target_dir = os.path.join(root_dir, f'WES_dataset/ERA5/FLLJ_{case}')\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    tp.to_netcdf(os.path.join(target_dir, 'turbine_power.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TabNet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
